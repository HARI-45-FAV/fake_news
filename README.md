
# ğŸ“˜ Fake News Detection Using DistilBERT

### **Cross-Domain Fake News Classification with Advanced Evaluation Metrics**

**Project ID: 25SK16** | **Course: CS3103 â€” Machine Learning Project**

---

## â­ Overview

This project builds a **robust, cross-domain Fake News Detection system** using a fine-tuned **DistilBERT transformer model**.
It performs:

* âš¡ High-accuracy binary classification â†’ *Fake (0)* or *Real (1)*
* ğŸŒ Cross-domain testing on unseen datasets
* ğŸ“Š Advanced ML metrics (Macro-F1, AUROC, ECE, Brier Score, Robustness Indices)
* ğŸ§  Explainability via LIME
* ğŸ¨ Full Streamlit dashboard with 20+ analytics graphs

---

# ğŸ“ Folder Structure

```
Fake-News-Detection/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ fake.csv
â”‚   â”œâ”€â”€ True.csv
â”‚   â”œâ”€â”€ gossipcop_fake.csv
â”‚   â”œâ”€â”€ gossipcop_real.csv
â”‚   â”œâ”€â”€ train (3).csv
â”‚   â”œâ”€â”€ valid.csv
â”‚   â””â”€â”€ combined_news.csv        # Final cleaned training dataset
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ distilbert_generalized/  # Trained checkpoint (BERT tokenizer + model)
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ training_history.csv
â”‚   â”œâ”€â”€ classification_report.csv
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â””â”€â”€ calibration_bins.csv
â”‚
â”œâ”€â”€ artifacts_test/
â”‚   â”œâ”€â”€ classification_report_test.csv
â”‚   â”œâ”€â”€ confusion_matrix_test.png
â”‚   â”œâ”€â”€ roc_curve_test.png
â”‚   â”œâ”€â”€ accuracies.csv
â”‚   â””â”€â”€ combined_summary.json
â”‚
â”œâ”€â”€ app.py                       # Streamlit Visualization Dashboard
â”œâ”€â”€ train_distilbert.py          # Main Training + Evaluation Script
â”œâ”€â”€ prepare_dataset.py           # Dataset merging & cleaning
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# ğŸ“¦ Datasets Used

The project uses **three industry-standard Fake News datasets**:

---

### **1ï¸âƒ£ LIAR Dataset**

* Short political statements with verdict labels
* ğŸ”— **ACL Paper:** [https://aclanthology.org/P17-2067/](https://aclanthology.org/P17-2067/)
* ğŸ”— **Kaggle:** [https://www.kaggle.com/datasets/armagansalman/liar-dataset](https://www.kaggle.com/datasets/armagansalman/liar-dataset)

---

### **2ï¸âƒ£ ISOT Fake News Dataset**

* Real & fake news from mainstream media
* ğŸ”— **Official Dataset:** [https://www.uvic.ca/engineering/ece/isot/datasets/fake-news/index.php](https://www.uvic.ca/engineering/ece/isot/datasets/fake-news/index.php)
* ğŸ”— **Kaggle:** [https://www.kaggle.com/datasets/emineyetm/fake-news-detection-datasets](https://www.kaggle.com/datasets/emineyetm/fake-news-detection-datasets)

---

### **3ï¸âƒ£ GossipCop (FakeNewsNet)**

* Fake celebrity news dataset
* ğŸ”— **Research Paper:** [https://arxiv.org/abs/1809.01286](https://arxiv.org/abs/1809.01286)
* ğŸ”— **GitHub:** [https://github.com/KaiDMML/FakeNewsNet](https://github.com/KaiDMML/FakeNewsNet)

---

# ğŸ§¹ Dataset Preparation Pipeline (prepare_dataset.py)

The script:

* Automatically detects **text** & **label** columns
* Merges 6+ datasets
* Standardizes labels to **0 = Fake, 1 = Real**
* Cleans and saves the final file:

```
data/combined_news.csv
```

---

# ğŸ”¥ Methodology 

### **1ï¸âƒ£ Raw Datasets Collection**

LIAR, ISOT, GossipCop datasets imported and merged.

### **2ï¸âƒ£ Label Mapping & Column Detection**

Automatic detection of:

* Correct text column
* Correct label column

### **3ï¸âƒ£ Cleaned Combined Dataset**

Final file with:

* ~67,000 cleaned records
* Balanced fake/real labels

### **4ï¸âƒ£ BERT Tokenization**

Using:

* DistilBertTokenizerFast
* 192 max sequence length

### **5ï¸âƒ£ DistilBERT Fine-Tuning**

Training on:

* 2 epochs
* AdamW optimizer
* Linear warmup scheduler
* Mixed precision (AMP)

### **6ï¸âƒ£ Training Evaluation**

Metrics computed:

* Accuracy
* Macro-F1
* Balanced Accuracy
* AUROC
* Confusion Matrix
* ROC Curve

### **7ï¸âƒ£ Cross-Domain Test Evaluation**

Generalization tested on **train(3).csv**:

* Reports all metrics again
* Computes domain-shift robustness:

  * Accuracy Drop
  * AUROC Drop
  * Worst-Group Accuracy (WGA)

### **8ï¸âƒ£ Streamlit Visualization**

Interactive dashboard with:

* Heatmaps
* ROC curves
* Training history
* LIME explanation
* WordCloud
* Probability graphs

---

# ğŸ§  Model Architecture (DistilBERT)

* 6 transformer layers
* 66M parameters
* Pre-classifier dense layer (ReLU)
* Final classification head â†’ 2 outputs

---

# ğŸ“Š Evaluation Metrics

### **Model Performance Metrics**

* Accuracy
* Precision
* Recall
* Macro-F1
* AUROC
* Balanced Accuracy

### **Visualizations Saved**

* Confusion Matrix
* ROC Curve
* PR Curve
* Loss vs Epochs
* Label Distribution
* Text-Length Distribution

---

# â–¶ï¸ How to Run the Project

---

## **1ï¸âƒ£ Install Requirements**

```bash
pip install -r requirements.txt
```

---

## **2ï¸âƒ£ Prepare Dataset**

```bash
python prepare_dataset.py
```

Output:

```
data/combined_news.csv
```

---

## **3ï¸âƒ£ Train DistilBERT**

```bash
python train_distilbert.py \
  --train_file data/combined_news.csv \
  --test_file "data/train (3).csv" \
  --epochs 2 \
  --batch_size 32
```

---

## **4ï¸âƒ£ Run Streamlit Dashboard**

```bash
streamlit run app.py
```

Open the URL shown in the terminal.

---


---





